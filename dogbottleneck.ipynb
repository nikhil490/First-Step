{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bottleneck = np.load('bottleneck_features/DogResnet50Data.npz')\n",
    "train_Resnet50 = bottleneck['train']\n",
    "valid_Resnet50 = bottleneck['valid']\n",
    "test_Resnet50 = bottleneck['test']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(GlobalAveragePooling2D(input_shape = train_Resnet50.shape[1:]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(133,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_file = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']),133)\n",
    "    return dog_file,dog_targets\n",
    "\n",
    "# load train,validation and test datasets\n",
    "train,train_target = load_dataset('dogImages/train')\n",
    "test,test_target = load_dataset('dogImages/test')\n",
    "valid,valid_target = load_dataset('dogImages/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train, valid, test])))\n",
    "print('There are %d training dog images.' % len(train))\n",
    "print('There are %d validation dog images.' % len(valid))\n",
    "print('There are %d test dog images.'% len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/12\n",
      "6680/6680 [==============================] - 4s 587us/step - loss: 0.2070 - accuracy: 0.9320 - val_loss: 0.7684 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76841, saving model to weights.best.dog.hdf5\n",
      "Epoch 2/12\n",
      "6680/6680 [==============================] - 4s 547us/step - loss: 0.1669 - accuracy: 0.9484 - val_loss: 0.7366 - val_accuracy: 0.7856\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76841 to 0.73656, saving model to weights.best.dog.hdf5\n",
      "Epoch 3/12\n",
      "6680/6680 [==============================] - 4s 571us/step - loss: 0.1554 - accuracy: 0.9472 - val_loss: 0.7633 - val_accuracy: 0.7892\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.73656\n",
      "Epoch 4/12\n",
      "6680/6680 [==============================] - 4s 545us/step - loss: 0.1435 - accuracy: 0.9504 - val_loss: 0.7695 - val_accuracy: 0.8060\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.73656\n",
      "Epoch 5/12\n",
      "6680/6680 [==============================] - 4s 566us/step - loss: 0.1183 - accuracy: 0.9596 - val_loss: 0.7340 - val_accuracy: 0.8156\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73656 to 0.73404, saving model to weights.best.dog.hdf5\n",
      "Epoch 6/12\n",
      "6680/6680 [==============================] - 4s 573us/step - loss: 0.1118 - accuracy: 0.9660 - val_loss: 0.7992 - val_accuracy: 0.7964\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.73404\n",
      "Epoch 7/12\n",
      "6680/6680 [==============================] - 4s 571us/step - loss: 0.1125 - accuracy: 0.9645 - val_loss: 0.7248 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73404 to 0.72481, saving model to weights.best.dog.hdf5\n",
      "Epoch 8/12\n",
      "6680/6680 [==============================] - 4s 547us/step - loss: 0.0939 - accuracy: 0.9705 - val_loss: 0.7874 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.72481\n",
      "Epoch 9/12\n",
      "6680/6680 [==============================] - 4s 574us/step - loss: 0.1075 - accuracy: 0.9672 - val_loss: 0.8466 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72481\n",
      "Epoch 10/12\n",
      "6680/6680 [==============================] - 4s 555us/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.8331 - val_accuracy: 0.7976\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72481\n",
      "Epoch 11/12\n",
      "6680/6680 [==============================] - 4s 615us/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 0.8777 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72481\n",
      "Epoch 12/12\n",
      "6680/6680 [==============================] - 4s 548us/step - loss: 0.0984 - accuracy: 0.9662 - val_loss: 0.9072 - val_accuracy: 0.7964\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22b05d65c48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "\n",
    "checkp = ModelCheckpoint(filepath = 'weights.best.dog.hdf5',\n",
    "                        verbose = 1, save_best_only = True)\n",
    "\n",
    "model.fit(train_Resnet50,train_target,\n",
    "         validation_data = (valid_Resnet50,valid_target),\n",
    "         epochs = 12, batch_size = 20 , callbacks = [checkp],verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of test 0.9199533314225776, accurace_test 0.8133971095085144\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_Resnet50,test_target,verbose = 0)\n",
    "print(f'loss of test {score[0]}, accurace_test {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow2)",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
