{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "airbnb_pricepredict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL0I6ugUSTWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "58de485f-e767-476d-c365-8756f62d3b2c"
      },
      "source": [
        "!git clone -l -s git://github.com/nikhil490/First-Step.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 85 (delta 24), reused 15 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (85/85), 5.33 MiB | 4.88 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "/content/cloned-repo/cloned-repo/cloned-repo/cloned-repo\n",
            "'airbnb (1).csv'\t  GradientDescentTensorFlow.ipynb\n",
            " airbnb1.csv\t\t  logistic_regression_tf.ipynb\n",
            " airbnb.csv\t\t  multilayer_iris_dataset.ipynb\n",
            " airbnb_edited.ipynb\t  new_list.csv\n",
            " airbnb.ipynb\t\t  README.md\n",
            " FuelConsumptionCo2.csv   src-checkpoint.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAAtv_MwTfni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h0IjrvMT4Um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "95510b74-db8d-44d7-d38d-85932cf0cd58"
      },
      "source": [
        "data = pd.read_csv('airbnb1.csv')\n",
        "data.describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>distance_km</th>\n",
              "      <th>price</th>\n",
              "      <th>room_type_Entire home/apt</th>\n",
              "      <th>room_type_Private room</th>\n",
              "      <th>room_type_Shared room</th>\n",
              "      <th>amenities</th>\n",
              "      <th>requires_license</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>guests_included</th>\n",
              "      <th>extra_people</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>require_guest_phone_verification</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>host_total_listings_count</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>is_location_exact</th>\n",
              "      <th>host_is_superhost</th>\n",
              "      <th>maximum_nights</th>\n",
              "      <th>bed_type_Airbed</th>\n",
              "      <th>bed_type_Couch</th>\n",
              "      <th>bed_type_Futon</th>\n",
              "      <th>bed_type_Pull-out Sofa</th>\n",
              "      <th>bed_type_Real Bed</th>\n",
              "      <th>property_type_Aparthotel</th>\n",
              "      <th>property_type_Apartment</th>\n",
              "      <th>property_type_Barn</th>\n",
              "      <th>property_type_Bed and breakfast</th>\n",
              "      <th>property_type_Boat</th>\n",
              "      <th>property_type_Boutique hotel</th>\n",
              "      <th>property_type_Bungalow</th>\n",
              "      <th>property_type_Cabin</th>\n",
              "      <th>property_type_Camper/RV</th>\n",
              "      <th>property_type_Casa particular (Cuba)</th>\n",
              "      <th>property_type_Castle</th>\n",
              "      <th>property_type_Cave</th>\n",
              "      <th>property_type_Chalet</th>\n",
              "      <th>property_type_Condominium</th>\n",
              "      <th>property_type_Cottage</th>\n",
              "      <th>property_type_Guest suite</th>\n",
              "      <th>property_type_Guesthouse</th>\n",
              "      <th>property_type_Hostel</th>\n",
              "      <th>property_type_Hotel</th>\n",
              "      <th>property_type_House</th>\n",
              "      <th>property_type_Houseboat</th>\n",
              "      <th>property_type_In-law</th>\n",
              "      <th>property_type_Island</th>\n",
              "      <th>property_type_Loft</th>\n",
              "      <th>property_type_Other</th>\n",
              "      <th>property_type_Pension (South Korea)</th>\n",
              "      <th>property_type_Resort</th>\n",
              "      <th>property_type_Serviced apartment</th>\n",
              "      <th>property_type_Tiny house</th>\n",
              "      <th>property_type_Tipi</th>\n",
              "      <th>property_type_Townhouse</th>\n",
              "      <th>property_type_Train</th>\n",
              "      <th>property_type_Villa</th>\n",
              "      <th>cancellation_policy_flexible</th>\n",
              "      <th>cancellation_policy_moderate</th>\n",
              "      <th>cancellation_policy_strict_14_with_grace_period</th>\n",
              "      <th>cancellation_policy_super_strict_30</th>\n",
              "      <th>cancellation_policy_super_strict_60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.000000</td>\n",
              "      <td>19775.0</td>\n",
              "      <td>19775.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11444.838432</td>\n",
              "      <td>0.996869</td>\n",
              "      <td>16.116511</td>\n",
              "      <td>6.612339</td>\n",
              "      <td>1.578407</td>\n",
              "      <td>72.505082</td>\n",
              "      <td>4.365445</td>\n",
              "      <td>57.580480</td>\n",
              "      <td>0.481416</td>\n",
              "      <td>0.518584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.838736</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.304779</td>\n",
              "      <td>1.302149</td>\n",
              "      <td>7.917472</td>\n",
              "      <td>95.134109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.080126</td>\n",
              "      <td>1.147863</td>\n",
              "      <td>1.554488</td>\n",
              "      <td>2.581138</td>\n",
              "      <td>1.711504</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.388875</td>\n",
              "      <td>0.744678</td>\n",
              "      <td>0.126776</td>\n",
              "      <td>618.716308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950341</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021087</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.410872</td>\n",
              "      <td>0.315803</td>\n",
              "      <td>0.273325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6445.588185</td>\n",
              "      <td>1.301172</td>\n",
              "      <td>31.618719</td>\n",
              "      <td>16.417732</td>\n",
              "      <td>1.961295</td>\n",
              "      <td>114.784876</td>\n",
              "      <td>2.321267</td>\n",
              "      <td>46.561041</td>\n",
              "      <td>0.499667</td>\n",
              "      <td>0.499667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.733732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.460325</td>\n",
              "      <td>0.686961</td>\n",
              "      <td>10.056459</td>\n",
              "      <td>6.113820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263436</td>\n",
              "      <td>0.594964</td>\n",
              "      <td>0.979176</td>\n",
              "      <td>1.324768</td>\n",
              "      <td>2.382965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.487507</td>\n",
              "      <td>0.436053</td>\n",
              "      <td>0.332731</td>\n",
              "      <td>972.891596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492005</td>\n",
              "      <td>0.464847</td>\n",
              "      <td>0.445678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5859.500000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.953777</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11557.000000</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.049904</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1124.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17023.500000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>5.428898</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22551.000000</td>\n",
              "      <td>10.710000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>23.146792</td>\n",
              "      <td>1500.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  ...  cancellation_policy_super_strict_60\n",
              "count  19775.000000  ...                              19775.0\n",
              "mean   11444.838432  ...                                  0.0\n",
              "std     6445.588185  ...                                  0.0\n",
              "min        1.000000  ...                                  0.0\n",
              "25%     5859.500000  ...                                  0.0\n",
              "50%    11557.000000  ...                                  0.0\n",
              "75%    17023.500000  ...                                  0.0\n",
              "max    22551.000000  ...                                  0.0\n",
              "\n",
              "[8 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMH-ItG85F6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsuqCCCNUGXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.drop([\"price\"],axis=1)\n",
        "y = data[\"price\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_VGvTKWU5sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test  = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h970khXU-sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e976c2d-388a-4702-ff10-58139f1ced06"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.metrics import mean_squared_error\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#set parameters\n",
        "batch_size = 32\n",
        "epochs = 25\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512,input_shape=(data.shape[1]-1,), activation= 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation= 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'relu'))\n",
        "\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.compile(loss = mean_squared_error,\n",
        "              optimizer = Adam(),\n",
        "              metrics=['mean_squared_error'])\n",
        "\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17797 samples, validate on 1978 samples\n",
            "Epoch 1/25\n",
            "17797/17797 [==============================] - 4s 233us/step - loss: 1512.2593 - mean_squared_error: 1512.2593 - val_loss: 1798.5413 - val_mean_squared_error: 1798.5413\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1798.54134, saving model to weights-improvement-01-1798.54.hdf5\n",
            "Epoch 2/25\n",
            "17797/17797 [==============================] - 3s 190us/step - loss: 1277.6936 - mean_squared_error: 1277.6936 - val_loss: 1789.4452 - val_mean_squared_error: 1789.4452\n",
            "\n",
            "Epoch 00002: val_loss improved from 1798.54134 to 1789.44521, saving model to weights-improvement-02-1789.45.hdf5\n",
            "Epoch 3/25\n",
            "17797/17797 [==============================] - 4s 204us/step - loss: 1259.0273 - mean_squared_error: 1259.0273 - val_loss: 1741.0779 - val_mean_squared_error: 1741.0779\n",
            "\n",
            "Epoch 00003: val_loss improved from 1789.44521 to 1741.07789, saving model to weights-improvement-03-1741.08.hdf5\n",
            "Epoch 4/25\n",
            "17797/17797 [==============================] - 3s 189us/step - loss: 1238.8006 - mean_squared_error: 1238.8006 - val_loss: 1720.1387 - val_mean_squared_error: 1720.1387\n",
            "\n",
            "Epoch 00004: val_loss improved from 1741.07789 to 1720.13873, saving model to weights-improvement-04-1720.14.hdf5\n",
            "Epoch 5/25\n",
            "17797/17797 [==============================] - 4s 199us/step - loss: 1220.4520 - mean_squared_error: 1220.4520 - val_loss: 1713.6567 - val_mean_squared_error: 1713.6567\n",
            "\n",
            "Epoch 00005: val_loss improved from 1720.13873 to 1713.65669, saving model to weights-improvement-05-1713.66.hdf5\n",
            "Epoch 6/25\n",
            "17797/17797 [==============================] - 4s 201us/step - loss: 1188.2225 - mean_squared_error: 1188.2225 - val_loss: 1686.3715 - val_mean_squared_error: 1686.3715\n",
            "\n",
            "Epoch 00006: val_loss improved from 1713.65669 to 1686.37147, saving model to weights-improvement-06-1686.37.hdf5\n",
            "Epoch 7/25\n",
            "17797/17797 [==============================] - 3s 192us/step - loss: 1190.2643 - mean_squared_error: 1190.2643 - val_loss: 1672.1644 - val_mean_squared_error: 1672.1644\n",
            "\n",
            "Epoch 00007: val_loss improved from 1686.37147 to 1672.16437, saving model to weights-improvement-07-1672.16.hdf5\n",
            "Epoch 8/25\n",
            "17797/17797 [==============================] - 4s 207us/step - loss: 1147.4453 - mean_squared_error: 1147.4453 - val_loss: 1664.5593 - val_mean_squared_error: 1664.5593\n",
            "\n",
            "Epoch 00008: val_loss improved from 1672.16437 to 1664.55927, saving model to weights-improvement-08-1664.56.hdf5\n",
            "Epoch 9/25\n",
            "17797/17797 [==============================] - 4s 197us/step - loss: 1160.7069 - mean_squared_error: 1160.7069 - val_loss: 1638.3161 - val_mean_squared_error: 1638.3161\n",
            "\n",
            "Epoch 00009: val_loss improved from 1664.55927 to 1638.31607, saving model to weights-improvement-09-1638.32.hdf5\n",
            "Epoch 10/25\n",
            "17797/17797 [==============================] - 4s 199us/step - loss: 1124.7796 - mean_squared_error: 1124.7796 - val_loss: 1626.8077 - val_mean_squared_error: 1626.8077\n",
            "\n",
            "Epoch 00010: val_loss improved from 1638.31607 to 1626.80769, saving model to weights-improvement-10-1626.81.hdf5\n",
            "Epoch 11/25\n",
            "17797/17797 [==============================] - 4s 198us/step - loss: 1120.4599 - mean_squared_error: 1120.4599 - val_loss: 1654.0062 - val_mean_squared_error: 1654.0062\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1626.80769\n",
            "Epoch 12/25\n",
            "17797/17797 [==============================] - 4s 203us/step - loss: 1109.6352 - mean_squared_error: 1109.6352 - val_loss: 1625.5191 - val_mean_squared_error: 1625.5191\n",
            "\n",
            "Epoch 00012: val_loss improved from 1626.80769 to 1625.51906, saving model to weights-improvement-12-1625.52.hdf5\n",
            "Epoch 13/25\n",
            "17797/17797 [==============================] - 4s 207us/step - loss: 1089.1591 - mean_squared_error: 1089.1591 - val_loss: 1643.4840 - val_mean_squared_error: 1643.4840\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1625.51906\n",
            "Epoch 14/25\n",
            "17797/17797 [==============================] - 3s 195us/step - loss: 1086.9483 - mean_squared_error: 1086.9483 - val_loss: 1687.8354 - val_mean_squared_error: 1687.8354\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1625.51906\n",
            "Epoch 15/25\n",
            "17797/17797 [==============================] - 4s 220us/step - loss: 1079.3288 - mean_squared_error: 1079.3288 - val_loss: 1597.9505 - val_mean_squared_error: 1597.9505\n",
            "\n",
            "Epoch 00015: val_loss improved from 1625.51906 to 1597.95053, saving model to weights-improvement-15-1597.95.hdf5\n",
            "Epoch 16/25\n",
            "17797/17797 [==============================] - 4s 217us/step - loss: 1049.4287 - mean_squared_error: 1049.4287 - val_loss: 1606.0087 - val_mean_squared_error: 1606.0087\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1597.95053\n",
            "Epoch 17/25\n",
            "17797/17797 [==============================] - 4s 202us/step - loss: 1039.4549 - mean_squared_error: 1039.4549 - val_loss: 1613.3675 - val_mean_squared_error: 1613.3675\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1597.95053\n",
            "Epoch 18/25\n",
            "17797/17797 [==============================] - 3s 195us/step - loss: 1043.4267 - mean_squared_error: 1043.4267 - val_loss: 1620.8813 - val_mean_squared_error: 1620.8813\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1597.95053\n",
            "Epoch 19/25\n",
            "17797/17797 [==============================] - 4s 199us/step - loss: 1035.5999 - mean_squared_error: 1035.5999 - val_loss: 1616.5481 - val_mean_squared_error: 1616.5481\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1597.95053\n",
            "Epoch 20/25\n",
            "17797/17797 [==============================] - 4s 201us/step - loss: 1028.8962 - mean_squared_error: 1028.8962 - val_loss: 1615.7426 - val_mean_squared_error: 1615.7426\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1597.95053\n",
            "Epoch 21/25\n",
            "17797/17797 [==============================] - 3s 188us/step - loss: 1006.8006 - mean_squared_error: 1006.8006 - val_loss: 1663.3121 - val_mean_squared_error: 1663.3121\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1597.95053\n",
            "Epoch 22/25\n",
            "17797/17797 [==============================] - 4s 207us/step - loss: 1015.9354 - mean_squared_error: 1015.9354 - val_loss: 1673.6472 - val_mean_squared_error: 1673.6472\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1597.95053\n",
            "Epoch 23/25\n",
            "17797/17797 [==============================] - 3s 193us/step - loss: 995.1241 - mean_squared_error: 995.1241 - val_loss: 1598.2443 - val_mean_squared_error: 1598.2443\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1597.95053\n",
            "Epoch 24/25\n",
            "17797/17797 [==============================] - 4s 200us/step - loss: 999.4700 - mean_squared_error: 999.4700 - val_loss: 1580.7728 - val_mean_squared_error: 1580.7728\n",
            "\n",
            "Epoch 00024: val_loss improved from 1597.95053 to 1580.77284, saving model to weights-improvement-24-1580.77.hdf5\n",
            "Epoch 25/25\n",
            "17797/17797 [==============================] - 3s 196us/step - loss: 975.1982 - mean_squared_error: 975.1982 - val_loss: 1629.3890 - val_mean_squared_error: 1629.3890\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1580.77284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUX5fhAzVIrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "faaf181f-8b5d-4035-a64a-f3537758462e"
      },
      "source": [
        "#plot training history\n",
        "figsize=(10,5)\n",
        "ax,_ = plt.subplots(figsize=figsize)\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('modelloss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'],loc='upperleft')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Unrecognized location 'upperleft'. Falling back on 'best'; valid locations are\n",
            "\tbest\n",
            "\tupper right\n",
            "\tupper left\n",
            "\tlower left\n",
            "\tlower right\n",
            "\tright\n",
            "\tcenter left\n",
            "\tcenter right\n",
            "\tlower center\n",
            "\tupper center\n",
            "\tcenter\n",
            "This will raise an exception in 3.3.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAFNCAYAAAC9jTMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlVxYVsmVaT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "7072d783-af3a-478d-f1bd-06fc9deef627"
      },
      "source": [
        "ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'airbnb (1).csv'                       weights-improvement-02-1789.45.hdf5\n",
            " airbnb1.csv                           weights-improvement-03-1741.08.hdf5\n",
            " airbnb.csv                            weights-improvement-04-1720.14.hdf5\n",
            " airbnb_edited.ipynb                   weights-improvement-05-1713.66.hdf5\n",
            " airbnb.ipynb                          weights-improvement-06-1686.37.hdf5\n",
            " FuelConsumptionCo2.csv                weights-improvement-07-1672.16.hdf5\n",
            " GradientDescentTensorFlow.ipynb       weights-improvement-08-1664.56.hdf5\n",
            " logistic_regression_tf.ipynb          weights-improvement-09-1638.32.hdf5\n",
            " multilayer_iris_dataset.ipynb         weights-improvement-10-1626.81.hdf5\n",
            " new_list.csv                          weights-improvement-12-1625.52.hdf5\n",
            " README.md                             weights-improvement-15-1597.95.hdf5\n",
            " src-checkpoint.ipynb                  weights-improvement-24-1580.77.hdf5\n",
            " weights-improvement-01-1798.54.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFvCypNsYZr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3534409e-f465-407c-a719-7958cbc8d0c3"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "\n",
        "saved_loss_file = None\n",
        "loss_min = 100000\n",
        "# r=root, d=directories, f = files\n",
        "for r, d, f in os.walk('./'):\n",
        "    for file in f:\n",
        "        if '.hdf5' in file:\n",
        "            filename = os.path.join(r, file)\n",
        "            loss = int(filename.split('-')[3].split('.')[0])\n",
        "            if loss < loss_min:\n",
        "                loss_min = loss\n",
        "                saved_loss_file = filename\n",
        "                \n",
        "print(\"Saved min loss : \",loss_min,\"\\nFile :\",saved_loss_file)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved min loss :  1580 \n",
            "File : ./weights-improvement-24-1580.77.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkFv2BjlYhZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "from keras.models import load_model\n",
        "best_model = load_model(saved_loss_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfPtEUaYpOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction\n",
        "pred_mlp = best_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZwN2CysYtYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0b99fcd9-9476-4bf1-cbf2-82c34c43c6b4"
      },
      "source": [
        "#evaluate\n",
        "print('\\n# Model Evaluate')\n",
        "results = best_model.evaluate(X_test, y_test)\n",
        "print('Test Mse Loss:', results[0])\n",
        "\n",
        "RMSE = np.sqrt(results[0])\n",
        "print(\"RMSE:\",RMSE)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Model Evaluate\n",
            "1978/1978 [==============================] - 0s 133us/step\n",
            "Test Mse Loss: 1580.7728402318078\n",
            "RMSE: 39.758934093255164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYm0SpCgAtkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}